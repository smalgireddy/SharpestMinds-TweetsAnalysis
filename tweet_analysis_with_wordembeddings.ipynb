{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from string import punctuation\n",
    "import collections, operator\n",
    "from scikitplot import plotters as skplt\n",
    "import nltk\n",
    "#scikit-learn package\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#keras\n",
    "from __future__ import print_function\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model, save_model, load_model\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, Conv2D, MaxPooling2D, Reshape, merge, BatchNormalization, concatenate\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Flatten, Lambda\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences, skipgrams, make_sampling_table\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from IPython.display import Image, display, SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils.data_utils import get_file\n",
    "#gensim\n",
    "import gensim\n",
    "from gensim.models import word2vec, Phrases, word2vec\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tweets data pre-processing step\n",
    "1. Loading the data from json files into dataframes\n",
    "2. Filtering the data with tweets text\n",
    "3. Seperating the data frames based on the tweets type\n",
    "4. finally 3 data frames with the following labels\n",
    "    * tweets_food\n",
    "        * Labels : healthy, junk, unhealthy\n",
    "    * tweets_borne\n",
    "        * Labels : relevant, irrelevant\n",
    "    * tweets_exercise\n",
    "        * Labels : relevant, irrelevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7294, 16)\n",
      "tweets with food dataframe shape is (7294, 16)\n",
      "tweets with borne dataframe shape is (470, 16)\n",
      "tweets with exercises dataframe shape is (2201, 16)\n",
      "(28246, 10)\n",
      "data with labels 26922\n",
      "removing data without labels\n",
      "after removing the shape of the data is(26922, 10)\n",
      "0    RT @_skull_queen_: So..... has anyone ever act...\n",
      "1    RT @_skull_queen_: So..... has anyone ever act...\n",
      "2    RT @_skull_queen_: So..... has anyone ever act...\n",
      "3    RT @_skull_queen_: So..... has anyone ever act...\n",
      "4    RT @_skull_queen_: So..... has anyone ever act...\n",
      "Name: tweets_data_text, dtype: object\n",
      "tweets with food dataframe shape is (19504, 2)\n",
      "tweets with borne dataframe shape is (16550, 2)\n",
      "tweets with exercises dataframe shape is (2469, 2)\n"
     ]
    }
   ],
   "source": [
    "#preparing the data\n",
    "#json reading using pandas\n",
    "tweets_pd = pd.read_json('classified_tweets_latest.json', orient='columns')\n",
    "tweets_pd.head()\n",
    "tweets_text = (tweets_pd['tweet'].apply(lambda tweet : eval(tweet))).apply(lambda tweet : tweet['text'])\n",
    "tweets_pd = tweets_pd.assign(tweets_text = tweets_text)\n",
    "#tweets_pd.label_data.value_counts()\n",
    "#missing values checking for label_data\n",
    "tweets_pd = tweets_pd.loc[tweets_pd['food'] != 'None']\n",
    "tweets_pd = tweets_pd.loc[tweets_pd['label_data'] != '']\n",
    "print(tweets_pd.shape)\n",
    "tweets_pd['label_data'] = tweets_pd.label_data.str.lower()\n",
    "tweets_pd['tweets_text'] = tweets_pd.tweets_text.apply(lambda x: ' '.join(re.sub(r\"([!@#$]+)|([^A-Za-z .*\\t])|(\\w+:\\/\\/\\S+)\",' ',x).split()))\n",
    "#after removing special characters, we left with plain data with alphanumeric characters\n",
    "#seperate the data based on their class\n",
    "tweets_pd_food = tweets_pd.loc[tweets_pd.food == '1']\n",
    "tweets_pd_borne = tweets_pd.loc[tweets_pd.borne == '1']\n",
    "tweets_pd_exercies = tweets_pd.loc[tweets_pd.exercise == '1']\n",
    "print(\"tweets with food dataframe shape is {}\".format(tweets_pd_food.shape))\n",
    "print(\"tweets with borne dataframe shape is {}\".format(tweets_pd_borne.shape))\n",
    "print(\"tweets with exercises dataframe shape is {}\".format(tweets_pd_exercies.shape))\n",
    "pd_792017 = pd.read_json('07292017.json', orient='columns')\n",
    "pd_8022017 = pd.read_json('08022017.json', orient='columns')\n",
    "pd_8072017 = pd.read_json('08072017.json', orient='columns')\n",
    "pd_8082017 = pd.read_json('08082017.json', orient='columns')\n",
    "pd_8242017 = pd.read_json('08242017.json', orient='columns')\n",
    "tweets_data = pd.concat([pd_792017, pd_8022017, pd_8072017, pd_8082017, pd_8242017], ignore_index=True)\n",
    "tweets_data_text = (tweets_data.tweet.apply(lambda tweet: eval(tweet))).apply(lambda text: text['text'])\n",
    "#data with 9 columns\n",
    "tweets_data = tweets_data.assign(tweets_data_text = tweets_data_text)\n",
    "#tweets_data_text.head()\n",
    "#change the labels into category codes\n",
    "tweets_data.food = tweets_data.food.astype(\"category\")\n",
    "print(tweets_data.shape)\n",
    "#remove the tweets without label_data\n",
    "print(\"data with labels {}\".format(sum(tweets_data['label_data'] != '')))\n",
    "print(\"removing data without labels\")\n",
    "#missing values checking for label_data\n",
    "tweets_data = tweets_data.loc[tweets_data['label_data'] != '']\n",
    "print(\"after removing the shape of the data is{}\".format(tweets_data.shape))\n",
    "tweets_data['label_data'] = tweets_data.label_data.str.lower()\n",
    "tweets_data['tweets_text'] = tweets_data.tweets_data_text.apply(lambda x: ' '.join(re.sub(r\"([!@#$]+)|([^A-Za-z .*\\t])|(\\w+:\\/\\/\\S+)\",' ',x).split()))\n",
    "print(tweets_data.tweets_data_text.head())\n",
    "#after removing special characters, we left with plain data with alphanumeric characters\n",
    "#seperate the data based on their class\n",
    "tweets_data_food = tweets_data.loc[tweets_data.food == 1]\n",
    "tweets_data_borne = tweets_data.loc[tweets_data.borne == 1]\n",
    "tweets_data_exercies = tweets_data.loc[tweets_data.exercise == 1]\n",
    "tweets_data_food = tweets_data_food[['label_data','tweets_text']]\n",
    "tweets_data_borne = tweets_data_borne[['label_data','tweets_text']]\n",
    "tweets_data_exercies = tweets_data_exercies[['label_data','tweets_text']]\n",
    "tweets_pd_food = tweets_pd_food[['label_data','tweets_text']]\n",
    "tweets_pd_borne = tweets_pd_borne[['label_data','tweets_text']]\n",
    "tweets_pd_exercies = tweets_pd_exercies[['label_data','tweets_text']]\n",
    "tweets_food = pd.concat([tweets_data_food, tweets_pd_food])\n",
    "tweets_borne = pd.concat([tweets_data_borne, tweets_pd_borne])\n",
    "tweets_exercies = pd.concat([tweets_data_exercies, tweets_pd_exercies])\n",
    "print(\"tweets with food dataframe shape is {}\".format(tweets_food.shape))\n",
    "print(\"tweets with borne dataframe shape is {}\".format(tweets_borne.shape))\n",
    "print(\"tweets with exercises dataframe shape is {}\".format(tweets_exercies.shape))\n",
    "#'healthy','unhealthy','junk','relevant','irrelevant'\n",
    "food_labels = ['healthy','unhealthy','junk']\n",
    "borne_labels = exercise_labels = ['junk','relevant','irrelevant']\n",
    "tweets_food = tweets_food.loc[tweets_food.label_data.isin(food_labels)]\n",
    "tweets_borne = tweets_borne.loc[tweets_borne.label_data.isin(borne_labels)]\n",
    "tweets_exercies = tweets_exercies.loc[tweets_exercies.label_data.isin(exercise_labels)]\n",
    "\n",
    "#tweets_data_food.label_data.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before removing(17894, 2)\n",
      "after removing(11102, 2)\n",
      "before removing(15505, 2)\n",
      "after removing(7071, 2)\n",
      "before removing(2447, 2)\n",
      "after removing(2049, 2)\n"
     ]
    }
   ],
   "source": [
    "#i find few duplicate rows, so deleting the duplicate rows\n",
    "tweets_food = tweets_food.reset_index(drop=True)\n",
    "print(\"before removing{}\".format(tweets_food.shape))\n",
    "tweets_food = tweets_food.drop_duplicates()\n",
    "print(\"after removing{}\".format(tweets_food.shape))\n",
    "print(\"before removing{}\".format(tweets_borne.shape))\n",
    "tweets_borne = tweets_borne.drop_duplicates()\n",
    "print(\"after removing{}\".format(tweets_borne.shape))\n",
    "print(\"before removing{}\".format(tweets_exercies.shape))\n",
    "tweets_exercies = tweets_exercies.drop_duplicates()\n",
    "print(\"after removing{}\".format(tweets_exercies.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD+CAYAAAAzmNK6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkgZlAEjSoAwASRrU/wf04c5Yfm5qqAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3367f23860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "food_label_count = tweets_food.label_data.value_counts()\n",
    "food_label_count.plot(kind = 'bar', rot=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD+CAYAAAAzmNK6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAGKtJREFUeJzt3X+UV3Wdx/HnSxCwtMAcDRncIaMf\nWCvaiHas1iwRsQ37ZdgPWdeW2sXNtrbCdjdTY4+drSyPSodWCjsVsZZHMsrwx1ZuoQxJKKjHSS0g\nhEkQ8xc68N4/Pp+RK84w3+/wnRnx83qc8z1z7+d+7v1+7tzv977u/dz7/X4VEZiZWXn2GewGmJnZ\n4HAAmJkVygFgZlYoB4CZWaEcAGZmhXIAmJkVygFgZlYoB4CZWaFqDgBJQyTdLum6PD5O0q2S2iX9\nQNKwXD48j7fn6S2VZZyXy++RdHKjV8bMzGo3tI665wJ3AS/J418CLomIhZK+AZwNzM1/t0TEKyVN\nz/XeL2kCMB04AjgUuEHSqyJie09PeNBBB0VLS0u962RmVrQVK1b8OSKaeqtXUwBIagZOBeYAn5Qk\n4ETgA7nKAuALpACYlocBrgYuy/WnAQsjYhtwv6R2YBLwm56et6Wlhba2tlqaaGZmmaQ/1FKv1i6g\nrwGfAXbk8ZcBD0dEZx5fB4zJw2OAtQB5+tZc/5nybuapNnympDZJbR0dHTU2z8zM6tVrAEh6B7Ap\nIlYMQHuIiHkR0RoRrU1NvZ7BmJlZH9XSBXQ88E5JU4ERpGsAXwdGShqaj/KbgfW5/npgLLBO0lDg\npcBDlfIu1XnMzGyA9XoGEBHnRURzRLSQLuLeFBEfBG4G3purzQCuzcOL8zh5+k2RvnN6MTA93yU0\nDhgP3NawNTEzs7rUcxfQrj4LLJT0ReB24MpcfiXwnXyRdzMpNIiI1ZIWAWuATmDW7u4AMjOz/qXn\n8w/CtLa2hu8CMjOrj6QVEdHaWz1/EtjMrFAOADOzQu3JNYAXnJbZPxnsJvSrBy4+dbCbYGbPIz4D\nMDMrlAPAzKxQDgAzs0I5AMzMCuUAMDMrlAPAzKxQDgAzs0I5AMzMCuUAMDMrlAPAzKxQDgAzs0I5\nAMzMCuUAMDMrlAPAzKxQDgAzs0L1GgCSRki6TdLvJK2WdEEu/7ak+yWtzI+JuVySLpXULmmVpKMr\ny5oh6d78mNHTc5qZWf+r5QdhtgEnRsSjkvYFbpH00zzt0xFx9S71TwHG58exwFzgWEkHAucDrUAA\nKyQtjogtjVgRMzOrT69nAJE8mkf3zY/d/ZL8NOCqPN8yYKSk0cDJwNKI2Jx3+kuBKXvWfDMz66ua\nrgFIGiJpJbCJtBO/NU+ak7t5LpE0PJeNAdZWZl+Xy3oq3/W5Zkpqk9TW0dFR5+qYmVmtagqAiNge\nEROBZmCSpNcB5wGvAY4BDgQ+24gGRcS8iGiNiNampqZGLNLMzLpR111AEfEwcDMwJSI25G6ebcC3\ngEm52npgbGW25lzWU7mZmQ2CWu4CapI0Mg/vB5wE3J379ZEk4DTgzjzLYuDMfDfQccDWiNgAXA9M\nljRK0ihgci4zM7NBUMtdQKOBBZKGkAJjUURcJ+kmSU2AgJXAx3L9JcBUoB14HDgLICI2S7oIWJ7r\nXRgRmxu3KmZmVo9eAyAiVgFHdVN+Yg/1A5jVw7T5wPw622hmZv3AnwQ2MyuUA8DMrFAOADOzQjkA\nzMwK5QAwMyuUA8DMrFAOADOzQjkAzMwK5QAwMyuUA8DMrFAOADOzQjkAzMwK5QAwMyuUA8DMrFAO\nADOzQjkAzMwK5QAwMyuUA8DMrFC1/Cj8CEm3SfqdpNWSLsjl4yTdKqld0g8kDcvlw/N4e57eUlnW\nebn8Hkkn99dKmZlZ72o5A9gGnBgRRwITgSmSjgO+BFwSEa8EtgBn5/pnA1ty+SW5HpImANOBI4Ap\nwBX5h+bNzGwQ9BoAkTyaR/fNjwBOBK7O5QuA0/LwtDxOnv42ScrlCyNiW0TcD7QDkxqyFmZmVreh\ntVTKR+orgFcClwO/Bx6OiM5cZR0wJg+PAdYCRESnpK3Ay3L5sspiq/NUn2smMBPgsMMOq3N1rGQt\ns38y2E3oVw9cfOpgN8FeYGq6CBwR2yNiItBMOmp/TX81KCLmRURrRLQ2NTX119OYmRWvrruAIuJh\n4GbgjcBISV1nEM3A+jy8HhgLkKe/FHioWt7NPGZmNsBquQuoSdLIPLwfcBJwFykI3purzQCuzcOL\n8zh5+k0REbl8er5LaBwwHritUStiZmb1qeUawGhgQb4OsA+wKCKuk7QGWCjpi8DtwJW5/pXAdyS1\nA5tJd/4QEaslLQLWAJ3ArIjY3tjVMTOzWvUaABGxCjiqm/L76OYunoh4EnhfD8uaA8ypv5lmZtZo\n/iSwmVmhHABmZoVyAJiZFcoBYGZWKAeAmVmhHABmZoVyAJiZFcoBYGZWKAeAmVmhHABmZoVyAJiZ\nFcoBYGZWKAeAmVmhHABmZoVyAJiZFcoBYGZWKAeAmVmhHABmZoWq5Ufhx0q6WdIaSaslnZvLvyBp\nvaSV+TG1Ms95ktol3SPp5Er5lFzWLml2/6ySmZnVopYfhe8EPhURv5V0ALBC0tI87ZKI+HK1sqQJ\npB+CPwI4FLhB0qvy5MuBk4B1wHJJiyNiTSNWxMzM6lPLj8JvADbk4b9IugsYs5tZpgELI2IbcL+k\ndnb+eHx7/jF5JC3MdR0AZmaDoK5rAJJagKOAW3PROZJWSZovaVQuGwOsrcy2Lpf1VL7rc8yU1Cap\nraOjo57mmZlZHWoOAEn7Az8EPhERjwBzgcOBiaQzhK80okERMS8iWiOitampqRGLNDOzbtRyDQBJ\n+5J2/t+NiB8BRMTGyvRvAtfl0fXA2MrszbmM3ZSbmdkAq+UuIAFXAndFxFcr5aMr1d4F3JmHFwPT\nJQ2XNA4YD9wGLAfGSxonaRjpQvHixqyGmZnVq5YzgOOBDwN3SFqZyz4HnCFpIhDAA8BHASJitaRF\npIu7ncCsiNgOIOkc4HpgCDA/IlY3cF3MzKwOtdwFdAugbiYt2c08c4A53ZQv2d18ZmY2cPxJYDOz\nQjkAzMwK5QAwMyuUA8DMrFAOADOzQjkAzMwK5QAwMyuUA8DMrFAOADOzQjkAzMwK5QAwMyuUA8DM\nrFAOADOzQjkAzMwK5QAwMyuUA8DMrFAOADOzQjkAzMwKVcuPwo+VdLOkNZJWSzo3lx8oaamke/Pf\nUblcki6V1C5plaSjK8uakevfK2lG/62WmZn1ppYzgE7gUxExATgOmCVpAjAbuDEixgM35nGAU4Dx\n+TETmAspMIDzgWOBScD5XaFhZmYDr9cAiIgNEfHbPPwX4C5gDDANWJCrLQBOy8PTgKsiWQaMlDQa\nOBlYGhGbI2ILsBSY0tC1MTOzmtV1DUBSC3AUcCtwSERsyJMeBA7Jw2OAtZXZ1uWynsp3fY6Zktok\ntXV0dNTTPDMzq0PNASBpf+CHwCci4pHqtIgIIBrRoIiYFxGtEdHa1NTUiEWamVk3agoASfuSdv7f\njYgf5eKNuWuH/HdTLl8PjK3M3pzLeio3M7NBUMtdQAKuBO6KiK9WJi0Guu7kmQFcWyk/M98NdByw\nNXcVXQ9MljQqX/ydnMvMzGwQDK2hzvHAh4E7JK3MZZ8DLgYWSTob+ANwep62BJgKtAOPA2cBRMRm\nSRcBy3O9CyNic0PWwszM6tZrAETELYB6mPy2buoHMKuHZc0H5tfTQDMz6x/+JLCZWaEcAGZmhXIA\nmJkVygFgZlYoB4CZWaEcAGZmhXIAmJkVygFgZlYoB4CZWaEcAGZmhXIAmJkVygFgZlYoB4CZWaEc\nAGZmhXIAmJkVygFgZlYoB4CZWaFq+U3g+ZI2SbqzUvYFSeslrcyPqZVp50lql3SPpJMr5VNyWbuk\n2Y1fFTMzq0ctZwDfBqZ0U35JREzMjyUAkiYA04Ej8jxXSBoiaQhwOXAKMAE4I9c1M7NBUstvAv9S\nUkuNy5sGLIyIbcD9ktqBSXlae0TcByBpYa67pu4Wm5lZQ+zJNYBzJK3KXUSjctkYYG2lzrpc1lO5\nmZkNkr4GwFzgcGAisAH4SqMaJGmmpDZJbR0dHY1arJmZ7aJPARARGyNie0TsAL7Jzm6e9cDYStXm\nXNZTeXfLnhcRrRHR2tTU1JfmmZlZDfoUAJJGV0bfBXTdIbQYmC5puKRxwHjgNmA5MF7SOEnDSBeK\nF/e92WZmtqd6vQgs6fvACcBBktYB5wMnSJoIBPAA8FGAiFgtaRHp4m4nMCsituflnANcDwwB5kfE\n6oavjZmZ1ayWu4DO6Kb4yt3UnwPM6aZ8CbCkrtaZmVm/8SeBzcwK5QAwMyuUA8DMrFAOADOzQjkA\nzMwK5QAwMyuUA8DMrFAOADOzQjkAzMwK5QAwMyuUA8DMrFAOADOzQjkAzMwK5QAwMyuUA8DMrFAO\nADOzQjkAzMwK5QAwMytUrwEgab6kTZLurJQdKGmppHvz31G5XJIuldQuaZWkoyvzzMj175U0o39W\nx8zMalXLGcC3gSm7lM0GboyI8cCNeRzgFGB8fswE5kIKDNKPyR8LTALO7woNMzMbHL0GQET8Eti8\nS/E0YEEeXgCcVim/KpJlwEhJo4GTgaURsTkitgBLeW6omJnZAOrrNYBDImJDHn4QOCQPjwHWVuqt\ny2U9lT+HpJmS2iS1dXR09LF5ZmbWmz2+CBwRAUQD2tK1vHkR0RoRrU1NTY1arJmZ7aKvAbAxd+2Q\n/27K5euBsZV6zbmsp3IzMxskfQ2AxUDXnTwzgGsr5Wfmu4GOA7bmrqLrgcmSRuWLv5NzmZmZDZKh\nvVWQ9H3gBOAgSetId/NcDCySdDbwB+D0XH0JMBVoBx4HzgKIiM2SLgKW53oXRsSuF5bNzGwA9RoA\nEXFGD5Pe1k3dAGb1sJz5wPy6WmdmZv3GnwQ2MyuUA8DMrFAOADOzQjkAzMwK5QAwMyuUA8DMrFAO\nADOzQjkAzMwK5QAwMyuUA8DMrFAOADOzQjkAzMwK5QAwMyuUA8DMrFAOADOzQjkAzMwK5QAwMyuU\nA8DMrFB7FACSHpB0h6SVktpy2YGSlkq6N/8dlcsl6VJJ7ZJWSTq6EStgZmZ904gzgLdGxMSIaM3j\ns4EbI2I8cGMeBzgFGJ8fM4G5DXhuMzPro/7oApoGLMjDC4DTKuVXRbIMGClpdD88v5mZ1WBPAyCA\nn0taIWlmLjskIjbk4QeBQ/LwGGBtZd51uexZJM2U1CapraOjYw+bZ2ZmPRm6h/O/KSLWSzoYWCrp\n7urEiAhJUc8CI2IeMA+gtbW1rnnNzKx2e3QGEBHr899NwDXAJGBjV9dO/rspV18PjK3M3pzLzMxs\nEPQ5ACS9WNIBXcPAZOBOYDEwI1ebAVybhxcDZ+a7gY4Dtla6iszMbIDtSRfQIcA1krqW872I+Jmk\n5cAiSWcDfwBOz/WXAFOBduBx4Kw9eG4zM9tDfQ6AiLgPOLKb8oeAt3VTHsCsvj6fmZk1lj8JbGZW\nKAeAmVmhHABmZoVyAJiZFcoBYGZWKAeAmVmhHABmZoVyAJiZFcoBYGZWqD39NlAzs4Zomf2TwW5C\nv3ng4lMHuwnd8hmAmVmhHABmZoVyAJiZFcoBYGZWKAeAmVmhHABmZoVyAJiZFcoBYGZWqAEPAElT\nJN0jqV3S7IF+fjMzSwY0ACQNAS4HTgEmAGdImjCQbTAzs2SgzwAmAe0RcV9EPAUsBKYNcBvMzIyB\n/y6gMcDayvg64NhqBUkzgZl59FFJ9wxQ2wbDQcCfB+rJ9KWBeqZiePvtvV7o2+6vaqn0vPsyuIiY\nB8wb7HYMBEltEdE62O2wvvH223t52yUD3QW0HhhbGW/OZWZmNsAGOgCWA+MljZM0DJgOLB7gNpiZ\nGQPcBRQRnZLOAa4HhgDzI2L1QLbheaaIrq4XMG+/vZe3HaCIGOw2mJnZIPAngc3MCuUAMDMrlAOg\nn0jaX9IB3ZSr66+kffJjSP6UNJJOkHShpNcMdJttcEkaLulASfsNdltKVX1fdleW36td7+FmSZMl\nHTp4Ld4zDoAGq7xw/gV4d6VcAJEvukSyIz+2R8T2XHVfYBTwojzfMEnDB2wFrG5d27YyXt15dO04\n9Nw5n6MZOBV4zoGDdW/XHbakYyS9V9LQPL6Pdtmh7071fdk1fzfv1a4LpweTvtbmVbnukIavYD97\n3n0QbG/X9cIBvggMk3QQsE9EbJI0GhgHtAFHA8cATwPvBK6OiPnAY4CA7ZIOBi4DbgK+IUnhq/Z1\nkTSkEq5U/4eVnUJEROSd9DM7iojYLulDpG31uYh4srvn2HWbVF4DzxretV3AMNInUp+MiA7S92Od\nDRwp6Qbgloh4tO6VLkj+31f//xOBk4CfAp27+f9XXwcvI+0L/wK8FTgMeBy4ISLWS3oL8A7gT8CH\ngGsj4iLgeGAW8B5JS4D/ADoav5b9x2cADVY50ruI9CI8Ezgnl70BOJf0pj8SmE160S0BTpD0ZuAh\n0ovvdcDnSTuBb3QdiQzYirwASDqS9KZ8RvV/WDmqq56Vbd/ljCxIZ2RdR5gjJB0m6dWSDsxlr5c0\nPg/vI2lq/tbbQyV9W9L/SfqhpDflOjOAFaTXyK+Ar+Sd0EjgcFIQjMHvz2fJR/v7Sxqdt8FoSadK\nOq3ypZIdwJOkgygkfTD//2+SNCN34ZwP/FuePor0PpwB7AecSNreR7HzK2lGA39H+uqafwdaJL0f\n+CHw38BHIuJjOcT3Kj4D6D9/Ih3dPwS8JJdtBraQPgOxkfTFeN8FkHQB8CbgCtJZwqnAlRFxqaSh\nEdE5wO3f60XE74DfAUh6MXAgcCiwjbR9jie92Tsj4ipJp5Le9E8B10TE90gBPSIvY3/gk8Db8zJu\nkvQN4D2k7145i3T0OBW4lfRdM/OAVcAU4B+AW3L5i0mfg/lXSf9F2sHMJe38r42IZf32j9l7nU3a\ncS8nheMqUrcZwDGSLia93w4AnpZ0HOks+0TS/3U68GbgN6Sd/heBVwIvB74eEQ9JuowUvqcAUyR9\njfRefQD4UUTsyNfnjiF9iHU7aVs+66xib+EA6D9bSUd0T5JfIOw8MtkvDz8FqZ+fFA7NQCdpB/Ew\n8AZJI3rqerDdk9QCLIiIvwE+A7wPuBdYRgqAy4CvAGsktZJO/z8JtABvlzQp13sRsIO0UzgiIt4i\n6Q3Ap3PZNXk5kLbhKyLiHEn7ko7oP0UKdUk6DHgU2BQRa/K2/z3wWtLZxktIIbIsn/V124VRqKGk\nE7XTJU0h7cSnA28EPkY6iv85qWvtpaRvH55BOuMeS9rR/5F05L42b8MRwOERsU7Sq0mhsJUUMJtJ\nr4VHSE+8I19beJh0hv40aZsNy9P3qp0/OAD601ZgOPAE6QUI6QVzOOnFtZV8ZEk6ing8j3eSwuEK\nUnAslvSuiHhs4Jr+gvEEO//HQ4AtETENQNJHgd9HxBfy+D8DHyT9/8cDR5B2/j/L8zaRjhZPkvQr\n0jbcSNqOfwRWSPoAz+4DfjPprOBcUjfC35MuHD5Mem2Qn+8J0rZ+mvRa2AY9Xz8o2J+B+/LwJNJO\n/VLSTngV6axrB+kg6wDSNvoxMId0c8WmvIwhwA2ksP8JqRsOUhdtc0S8T+lOrBvzfJvzX0jb5zFg\nRP5mg0eBl+eu36ER8XT/rHr/cAA0WOUoYCvphfh74Oh8tPF20hHFKNJO/hVds+XHWNJO4MV5WfPy\nxcJFpC4hq8+T7Lyj5k/AXfDMdZoHyTvr3Jc/HPg16YL7/wIbgNXsDOx9STvuqyLiE7s+Ub5oOwf4\nLnBdLh5DugHgDklPkrqcLiF1A3bd6hm5nQfnHcofgQ/nLqubIuLBhvwnXhi63lOQvkTy5oj4SLVC\nPsMS6X96N/ChiLinOj0i/ijpl6RtMRz4zzx5Xa5zBvDXpO13UH6ucZWn6SR1JUK6zvct0o0cHye9\nZvYaDoD+swU4ICJWS7qadGq5EriQdBSykdQt0XVqeQ3proMdkj5FOiokIuaS+oatfk+xc0f7GOnI\nj3zHz1+6xkk79nbgbyPi510zK32O4xHSKf4TpL7nT0g6Ild5OfBwRKwAbid1//wTcFye/mvgHyXd\nSDqqv5u0Q3mAvCPLbXmQnUe2V5MODF4N/KIh/4UXjkdJXTuQjto/lnfWO0hnVstIB1xjSd12vwCW\n5J39UNLR++dJZ2wbSV1Bx0bEbyvL/B9gMrCGdIfPPbnu++CZ7fWzvGwi4lekM8O9kr8LqJ/kO3q+\nHBHH9lrZ+kXur/1TRBwsaTpwekS8O087HvhWRHTdwz2SFNJjScEwlHREfwepG+hDEdEu6e2ku3c6\nSRccL4iI2/NznUbqT/5SpQ2vJZ2FbCJ1JTxWvS3Vaifp9cDlEfGWPN51p9xTpG1xOSkATiMdTG2V\nNAJ4DamL9RGgw///nRwA/UDSq4Brgc9ExI/z/eYi369c+ZDJEL8Y+09XV09EHJJ33O+MiI/naYcB\nZ0XEBZX6BwB/Q9pZbAHujognJO0XEU8MwiqY9SsHgJlZofxBEzOzQjkAzMwK5QAwMyuUA8DMrFAO\nADOzQjkAzMwK5QAwMyvU/wP/S4l8Q89gEwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3367f06da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "borne_label_count = tweets_borne.label_data.value_counts()\n",
    "borne_label_count.plot(kind = 'bar', rot=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD+CAYAAAAzmNK6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f33777e3da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exercies_label_count = tweets_exercies.label_data.value_counts()\n",
    "exercies_label_count.plot(kind = 'bar', rot=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_borne.label_data = tweets_borne.label_data.apply(lambda x : \"irrelevant\" if x == \"junk\" else x)\n",
    "tweets_exercies.label_data = tweets_exercies.label_data.apply(lambda x : \"irrelevant\" if x == \"junk\" else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature Engineering:\n",
    "1. tweets text tokenization\n",
    "2. tweets label conversion (one-hot encoding representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#since I am using skip-gram model I am not removing stop words\n",
    "#tokenize text into array of words\n",
    "stemmer=nltk.stem.SnowballStemmer('english')\n",
    "def tokenizeData(pdSeries):\n",
    "    #corpus = pdSeries.apply(lambda x: x.replace(\"\\n\",\"\").split())\n",
    "    corpus = [z.lower().replace('\\n','').split() for z in pdSeries]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#before jump into models, I convert the categorical classes into one-hot encoding format\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(tweets_food['label_data'])\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "labels = onehot_encoder.fit_transform(integer_encoded)\n",
    "#print(tweets_food['label_data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading pretraineed 200 dimentional glove  word embedding from standford NLP library\n",
    "1. assign the weights of each word vector of the corrsponding word if the word presents in word-embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading pretrained word embeddings\n",
    "embeddings_index = {}\n",
    "f = open('glove.twitter.27B.200d.txt')\n",
    "for line in f:\n",
    "    #print(line)\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(list(tweets_food.tweets_text))\n",
    "sequences = tokenizer.texts_to_sequences(list(tweets_food.tweets_text))\n",
    "word_index = tokenizer.word_index\n",
    "max_length = max(map(lambda x:len(x), tweets_food.tweets_text))\n",
    "data = pad_sequences(sequences, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#assin the embed vector to corresponding words in the tweet corpus\n",
    "embed_dim = 200\n",
    "embedding_matrix = np.random.random((len(word_index) + 1, embed_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to save the model\n",
    "def saveModel(file_name, model):\n",
    "    #saving model to HDF5\n",
    "    model.save(\"{}_model.h5\".format(file_name))\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_model(model, input_data, target, file_name):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(input_data, target, test_size = 0.2)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(train_x, train_y, batch_size= 20, validation_split= 0.2, epochs=20,  verbose=True)\n",
    "    score = model.evaluate(test_x, test_y, verbose = 0)\n",
    "    print(\"the loss {} and the accuracy score for test dataset is {}\".format(score[0], score[1]))\n",
    "    saveModel(file_name, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7104 samples, validate on 1777 samples\n",
      "Epoch 1/20\n",
      "7104/7104 [==============================] - 56s 8ms/step - loss: 0.5482 - acc: 0.7532 - val_loss: 0.5676 - val_acc: 0.7468\n",
      "Epoch 2/20\n",
      "7104/7104 [==============================] - 56s 8ms/step - loss: 0.5098 - acc: 0.7593 - val_loss: 0.5244 - val_acc: 0.7462\n",
      "Epoch 3/20\n",
      "7104/7104 [==============================] - 55s 8ms/step - loss: 0.4769 - acc: 0.7638 - val_loss: 0.5493 - val_acc: 0.7490\n",
      "Epoch 4/20\n",
      "7104/7104 [==============================] - 55s 8ms/step - loss: 0.5864 - acc: 0.7497 - val_loss: 0.8191 - val_acc: 0.7203\n",
      "Epoch 5/20\n",
      "7104/7104 [==============================] - 55s 8ms/step - loss: 0.5176 - acc: 0.7610 - val_loss: 0.5873 - val_acc: 0.7440\n",
      "Epoch 6/20\n",
      "7104/7104 [==============================] - 55s 8ms/step - loss: 0.4892 - acc: 0.7590 - val_loss: 0.5730 - val_acc: 0.7378\n",
      "Epoch 7/20\n",
      "7104/7104 [==============================] - 55s 8ms/step - loss: 0.4505 - acc: 0.7693 - val_loss: 0.5557 - val_acc: 0.7473\n",
      "Epoch 8/20\n",
      "7104/7104 [==============================] - 55s 8ms/step - loss: 0.5326 - acc: 0.7644 - val_loss: 0.6658 - val_acc: 0.7406\n",
      "Epoch 9/20\n",
      "7104/7104 [==============================] - 55s 8ms/step - loss: 0.4742 - acc: 0.7659 - val_loss: 0.6133 - val_acc: 0.7361\n",
      "Epoch 10/20\n",
      "7104/7104 [==============================] - 55s 8ms/step - loss: 0.4610 - acc: 0.7689 - val_loss: 0.7330 - val_acc: 0.7119\n",
      "Epoch 11/20\n",
      "7104/7104 [==============================] - 55s 8ms/step - loss: 0.4580 - acc: 0.7683 - val_loss: 0.6339 - val_acc: 0.7400\n",
      "Epoch 12/20\n",
      "7104/7104 [==============================] - 55s 8ms/step - loss: 0.4504 - acc: 0.7697 - val_loss: 0.6283 - val_acc: 0.7394\n",
      "Epoch 13/20\n",
      "7104/7104 [==============================] - 55s 8ms/step - loss: 0.4817 - acc: 0.7668 - val_loss: 0.6122 - val_acc: 0.7304\n",
      "Epoch 14/20\n",
      "7104/7104 [==============================] - 55s 8ms/step - loss: 0.4622 - acc: 0.7659 - val_loss: 0.5838 - val_acc: 0.7389\n",
      "Epoch 15/20\n",
      "7104/7104 [==============================] - 55s 8ms/step - loss: 0.4434 - acc: 0.7710 - val_loss: 0.5847 - val_acc: 0.7378\n",
      "Epoch 16/20\n",
      "7104/7104 [==============================] - 55s 8ms/step - loss: 0.4432 - acc: 0.7690 - val_loss: 0.5828 - val_acc: 0.7417\n",
      "Epoch 17/20\n",
      "7104/7104 [==============================] - 55s 8ms/step - loss: 0.4587 - acc: 0.7718 - val_loss: 0.6550 - val_acc: 0.7361\n",
      "Epoch 18/20\n",
      "7104/7104 [==============================] - 55s 8ms/step - loss: 0.4634 - acc: 0.7684 - val_loss: 0.5752 - val_acc: 0.7293\n",
      "Epoch 19/20\n",
      "7104/7104 [==============================] - 55s 8ms/step - loss: 0.4402 - acc: 0.7704 - val_loss: 0.6332 - val_acc: 0.7321\n",
      "Epoch 20/20\n",
      "7104/7104 [==============================] - 55s 8ms/step - loss: 0.4357 - acc: 0.7720 - val_loss: 0.5840 - val_acc: 0.7349\n",
      "the loss 0.5791972968987332 and the accuracy score for test dataset is 0.7460603332905982\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('glove_model.h5'):\n",
    "    model = load_model('glove_model.h5')\n",
    "    train_test_model(model, data, labels, \"glove\")\n",
    "else:\n",
    "    embedding_layer = Embedding(len(word_index) + 1,\n",
    "                                embed_dim,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=max_length,\n",
    "                                trainable=True)\n",
    "\n",
    "    sequence_input = Input(shape=(max_length,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    l_cov1= Conv1D(512, 4, activation='relu')(embedded_sequences)\n",
    "\n",
    "    l_pool1 = MaxPooling1D(4)(l_cov1)\n",
    "    l_cov2 = Conv1D(512, 5, activation='relu')(l_pool1)\n",
    "    l_pool2 = MaxPooling1D(5)(l_cov2)\n",
    "    l_cov3 = Conv1D(512, 5, padding=\"same\", activation='relu')(l_pool2)\n",
    "    l_pool3 = MaxPooling1D(35, padding=\"same\")(l_cov3)\n",
    "    l_flat = Flatten()(l_pool3)\n",
    "    dropout = Dropout(0.5)(l_flat)\n",
    "    l_dense = Dense(128, activation='relu')(dropout)\n",
    "    pred = Dense(3, activation='softmax', name = 'fc')(l_dense)\n",
    "    model = Model(sequence_input, pred)\n",
    "    print(model.summary())\n",
    "    train_test_model(model, data, labels, \"glove\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_x, test_x, train_y, test_y = train_test_split(data, labels, test_size = 0.2)\n",
    "# x_train, val_x, y_train, val_y = train_test_split(train_x, train_y, test_size = 0.2) \n",
    "# model.fit(x_train, y_train, validation_data=(val_x, val_y), epochs = 20, batch_size = 20, verbose = False)\n",
    "# score = model.evaluate(test_x, test_y, verbose = 0)\n",
    "# print(\"the loss {} and the accuracy score for test dataset is {}\".format(score[0], score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## till now we have seen the model perofrmance using tweet-glove preptrained glove-model now we will train the our own  word2vec:CBOW model for CNN classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_freq(all_vocabulary, freq):\n",
    "    sorted_vocab = sorted(dict(collections.Counter(all_vocabulary)).items(), key=operator.itemgetter(1))\n",
    "    final_vocab = [k for k,v in sorted_vocab if v>freq]\n",
    "    word_idx = dict((c, i + 1) for i, c in enumerate(final_vocab))\n",
    "    return final_vocab, word_idx\n",
    "\n",
    "final_vocab, word_idx = word_freq(np.hstack(tokenizeData(tweets_food.tweets_text)),2)\n",
    "vocab_len = len(final_vocab)\n",
    "\n",
    "def sentenceToVect(data, word_idx, final_vocab, maxlen=40):\n",
    "    X = []\n",
    "    notexist = len(final_vocab)+2\n",
    "    for sentences in data:\n",
    "        x=[]\n",
    "        for word in sentences.split(\" \"):\n",
    "            if word in final_vocab:\n",
    "                x.append(word_idx[word])\n",
    "            else:\n",
    "                x.append(notexist)\n",
    "        X.append(x)\n",
    "    return (pad_sequences(X, maxlen=maxlen))\n",
    "\n",
    "max_length = 50\n",
    "embed_dim = 150\n",
    "train_data = sentenceToVect(tweets_food.tweets_text, word_idx, final_vocab, max_length)\n",
    "final_vocab_len = vocab_len+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7104 samples, validate on 1777 samples\n",
      "Epoch 1/20\n",
      "7104/7104 [==============================] - 9s 1ms/step - loss: 0.8815 - acc: 0.7221 - val_loss: 0.5364 - val_acc: 0.7935\n",
      "Epoch 2/20\n",
      "7104/7104 [==============================] - 9s 1ms/step - loss: 0.5677 - acc: 0.7690 - val_loss: 0.4914 - val_acc: 0.8070\n",
      "Epoch 3/20\n",
      "7104/7104 [==============================] - 9s 1ms/step - loss: 0.4915 - acc: 0.8012 - val_loss: 0.4742 - val_acc: 0.8109\n",
      "Epoch 4/20\n",
      "7104/7104 [==============================] - 9s 1ms/step - loss: 0.4192 - acc: 0.8340 - val_loss: 0.4810 - val_acc: 0.8087\n",
      "Epoch 5/20\n",
      "7104/7104 [==============================] - 9s 1ms/step - loss: 0.3492 - acc: 0.8623 - val_loss: 0.5076 - val_acc: 0.7997\n",
      "Epoch 6/20\n",
      "7104/7104 [==============================] - 9s 1ms/step - loss: 0.2963 - acc: 0.8832 - val_loss: 0.5098 - val_acc: 0.8104\n",
      "Epoch 7/20\n",
      "7104/7104 [==============================] - 9s 1ms/step - loss: 0.2612 - acc: 0.9019 - val_loss: 0.5450 - val_acc: 0.8047\n",
      "Epoch 8/20\n",
      "7104/7104 [==============================] - 9s 1ms/step - loss: 0.2332 - acc: 0.9122 - val_loss: 0.5636 - val_acc: 0.7985\n",
      "Epoch 9/20\n",
      "7104/7104 [==============================] - 9s 1ms/step - loss: 0.2166 - acc: 0.9139 - val_loss: 0.6181 - val_acc: 0.7957  - ETA: 3s - loss: 0.2257 - ETA: 2s - loss: 0.2209 - - ETA: 1s -\n",
      "Epoch 10/20\n",
      "7104/7104 [==============================] - 9s 1ms/step - loss: 0.1853 - acc: 0.9298 - val_loss: 0.6180 - val_acc: 0.7946\n",
      "Epoch 11/20\n",
      "7104/7104 [==============================] - 9s 1ms/step - loss: 0.1884 - acc: 0.9286 - val_loss: 0.5816 - val_acc: 0.8025\n",
      "Epoch 12/20\n",
      "7104/7104 [==============================] - 9s 1ms/step - loss: 0.1621 - acc: 0.9386 - val_loss: 0.5962 - val_acc: 0.8098 ETA: 4s  - E\n",
      "Epoch 13/20\n",
      "7104/7104 [==============================] - 8s 1ms/step - loss: 0.1631 - acc: 0.9382 - val_loss: 0.5993 - val_acc: 0.8171- loss: 0.1577 - acc: 0 - ETA: 1s - loss: 0.1614 - acc: 0.9 - ETA: 1s - loss: 0.1611 - acc - ETA: 0s - loss: 0.1628 - acc: 0. - ETA: 0s - loss: 0.1625 - acc: \n",
      "Epoch 14/20\n",
      "7104/7104 [==============================] - 9s 1ms/step - loss: 0.1568 - acc: 0.9434 - val_loss: 0.6084 - val_acc: 0.8137- loss: 0.1547 - acc\n",
      "Epoch 15/20\n",
      "7104/7104 [==============================] - 9s 1ms/step - loss: 0.1463 - acc: 0.9430 - val_loss: 0.5918 - val_acc: 0.8188- - ETA: 0s - loss: 0.1456 - acc:\n",
      "Epoch 16/20\n",
      "7104/7104 [==============================] - 9s 1ms/step - loss: 0.1425 - acc: 0.9448 - val_loss: 0.7347 - val_acc: 0.7895\n",
      "Epoch 17/20\n",
      "7104/7104 [==============================] - 9s 1ms/step - loss: 0.1347 - acc: 0.9459 - val_loss: 0.6906 - val_acc: 0.8104\n",
      "Epoch 18/20\n",
      "7104/7104 [==============================] - 9s 1ms/step - loss: 0.1297 - acc: 0.9500 - val_loss: 0.6734 - val_acc: 0.8042\n",
      "Epoch 19/20\n",
      "7104/7104 [==============================] - 9s 1ms/step - loss: 0.1364 - acc: 0.9454 - val_loss: 0.6862 - val_acc: 0.8008\n",
      "Epoch 20/20\n",
      "7104/7104 [==============================] - 9s 1ms/step - loss: 0.1273 - acc: 0.9488 - val_loss: 0.7280 - val_acc: 0.7963\n",
      "the loss 0.6784045448822784 and the accuracy score for test dataset is 0.8135974786400741\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('wordembed_model.h5'):\n",
    "    model = load_model('wordembed_model.h5')\n",
    "    train_test_model(model, train_data, labels, \"wordembed\")\n",
    "else:\n",
    "    sequence_input = Input(shape=(max_length,embed_dim), dtype='float32')\n",
    "    from keras.layers.advanced_activations import LeakyReLU\n",
    "    filter_sizes = (3,5,5,7)\n",
    "    dropout_prob = [0.5,0.5]\n",
    "    graph_in = sequence_input\n",
    "    convs = []\n",
    "    mul = 1\n",
    "    for filter_s in filter_sizes:\n",
    "        conv = Conv1D(filters=32*mul,\n",
    "                             kernel_size=filter_s,\n",
    "                             padding='valid',\n",
    "                             activation='relu')(graph_in)\n",
    "        pool = MaxPooling1D(max_length-filter_s+1)(conv)\n",
    "        flattenMax = Flatten()(pool)\n",
    "        convs.append(flattenMax)\n",
    "        mul+=1\n",
    "    out = concatenate(convs, axis=1)    \n",
    "    graph = Model(graph_in, out, name=\"word_embed\")\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=final_vocab_len, #size of vocabulary\n",
    "                     output_dim = embed_dim,\n",
    "                     input_length = max_length,\n",
    "                     trainable=True))\n",
    "    model.add(Dropout(dropout_prob[0]))\n",
    "    model.add(graph)\n",
    "    model.add(Dense(128, kernel_initializer='uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_prob[1]))\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(LeakyReLU(alpha=.001))\n",
    "    model.add(Dense(3))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Activation('softmax'))\n",
    "    model.summary()\n",
    "    train_test_model(model, train_data, labels, \"wordembed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## word2vec- skip gram model\n",
    "1. given the target of the word predicts the context of the input word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_length = 15\n",
    "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~')\n",
    "tokenizer.fit_on_texts(tweets_food.tweets_text)\n",
    "sequences = tokenizer.texts_to_sequences(list(tweets_food.tweets_text))\n",
    "word_index = tokenizer.word_index\n",
    "data = pad_sequences(sequences, maxlen=max_length)\n",
    "#vocab size\n",
    "vocab_len = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_size = 200\n",
    "number_of_epochs = 20\n",
    "num_neg_samples = 4\n",
    "sampling_factor = 1e-1\n",
    "window_size = 4\n",
    "save_path = './tweets_food_model.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Embedding, Merge, Reshape\n",
    "def create_model():\n",
    "    target_word = Sequential()\n",
    "    target_word.add(Embedding(vocab_len, embedding_size, input_length=1))\n",
    "\n",
    "    context = Sequential()\n",
    "    context.add(Embedding(vocab_len, embedding_size, input_length=3))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Merge([target_word, context], mode='dot', dot_axes=2))\n",
    "    model.add(Reshape((1,), input_shape=(1, 1)))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    sampling_table = make_sampling_table(vocab_len, sampling_factor=sampling_factor)\n",
    "    for epoch in range(number_of_epochs):\n",
    "        loss = 0.\n",
    "        for i, sentence in enumerate(sequences):\n",
    "            if i % 500 == 0:\n",
    "                print('{}/{}'.format(i, len(sequences)))\n",
    "            couples, labels = skipgrams(sequence=sentence, vocabulary_size=vocab_len, window_size=window_size,\n",
    "                                        negative_samples=num_neg_samples, sampling_table=sampling_table)\n",
    "            if couples:\n",
    "                words, contexts = zip(*couples)\n",
    "                words = np.array(words, dtype=np.int32)\n",
    "                contexts = np.array(contexts, dtype=np.int32)\n",
    "                y = np.array(labels, dtype=np.int32)\n",
    "                loss += model.train_on_batch([words, contexts], y)\n",
    "        print('epoch finished: {} with loss: {}'.format(epoch, loss))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    with open(save_path, 'w') as f:\n",
    "        f.write(' '.join([str(vocab_len - 1), str(embedding_size)]))\n",
    "        f.write('\\n')\n",
    "        vectors = model.get_weights()[0]\n",
    "        for word, i in tokenizer.word_index.items():\n",
    "            f.write(word)\n",
    "            f.write(' ')\n",
    "            f.write(' '.join(map(str, list(vectors[0][i, :]))))\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load embedding as a dict\n",
    "def load_embedding(filename):\n",
    "    file = open(filename,'r')\n",
    "    lines = file.readlines()[1:]\n",
    "    file.close()\n",
    "    # create a map of words to vectors\n",
    "    embedding = dict()\n",
    "    for line in lines:\n",
    "        words = line.split()\n",
    "        # key is string word, value is numpy array for vector\n",
    "        embedding[words[0]] = np.asarray(words[1:], dtype='float32')\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for the Embedding layer from a loaded embedding\n",
    "def get_weight_matrix(embedding, vocab):\n",
    "    #total vocabulary size plus 0 for unknown words\n",
    "    vocab_size = len(vocab) + 1\n",
    "    #define weight matrix dimensions with all 0\n",
    "    weight_matrix = np.zeros((vocab_size, embedding_size))\n",
    "    #step vocab, store vectors using the Tokenizer's integer mapping\n",
    "    for word, i in vocab.items():\n",
    "        weight_matrix[i] = embedding.get(word)\n",
    "    return weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(save_path):\n",
    "    pass\n",
    "else:\n",
    "    model = create_model()\n",
    "    model = train_model(model)\n",
    "    save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load embedding from file and create the embedding layer\n",
    "raw_embedding = load_embedding('tweets_food_model.txt')\n",
    "embedding_vectors = get_weight_matrix(raw_embedding, tokenizer.word_index)\n",
    "embedding_layer = Embedding(vocab_len, embedding_size, weights=[embedding_vectors], input_length=max_length, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "def defineModel(max_sequence_length, embed_dim, embedding_layer):\n",
    "    sequence_input = Input(shape=(max_sequence_length,embed_dim), dtype='float32')\n",
    "    filter_sizes = (3,5,5,7)\n",
    "    dropout_prob = [0.5,0.5]\n",
    "    convs = []\n",
    "    mul = 1\n",
    "    for filter_s in filter_sizes:\n",
    "        conv = Conv1D(filters=32*mul,\n",
    "                             kernel_size=filter_s,\n",
    "                             padding='valid',\n",
    "                             activation='relu')(sequence_input)\n",
    "        pool = MaxPooling1D(max_length-filter_s)(conv)\n",
    "        flattenMax = Flatten()(pool)\n",
    "        convs.append(flattenMax)\n",
    "        mul+=1\n",
    "    out = concatenate(convs, axis=1)    \n",
    "    graph = Model(sequence_input, out, name=\"word2vec\")\n",
    "    model = Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    model.add(Dropout(dropout_prob[0]))\n",
    "    model.add(graph)\n",
    "    model.add(Dense(128, kernel_initializer='uniform'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LeakyReLU(alpha=.001))\n",
    "    model.add(Dense(3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7104 samples, validate on 1777 samples\n",
      "Epoch 1/20\n",
      "7104/7104 [==============================] - 3s 411us/step - loss: 0.2276 - acc: 0.9216 - val_loss: 0.0761 - val_acc: 0.9764\n",
      "Epoch 2/20\n",
      "7104/7104 [==============================] - 3s 361us/step - loss: 0.2104 - acc: 0.9251 - val_loss: 0.0760 - val_acc: 0.9758\n",
      "Epoch 3/20\n",
      "7104/7104 [==============================] - 3s 362us/step - loss: 0.1986 - acc: 0.9329 - val_loss: 0.0797 - val_acc: 0.9736\n",
      "Epoch 4/20\n",
      "7104/7104 [==============================] - 3s 361us/step - loss: 0.1934 - acc: 0.9319 - val_loss: 0.0859 - val_acc: 0.9730\n",
      "Epoch 5/20\n",
      "7104/7104 [==============================] - 3s 359us/step - loss: 0.1804 - acc: 0.9396 - val_loss: 0.0865 - val_acc: 0.9741\n",
      "Epoch 6/20\n",
      "7104/7104 [==============================] - 3s 359us/step - loss: 0.1723 - acc: 0.9407 - val_loss: 0.0927 - val_acc: 0.9679\n",
      "Epoch 7/20\n",
      "7104/7104 [==============================] - 3s 362us/step - loss: 0.1620 - acc: 0.9437 - val_loss: 0.0981 - val_acc: 0.9713\n",
      "Epoch 8/20\n",
      "7104/7104 [==============================] - 3s 362us/step - loss: 0.1693 - acc: 0.9419 - val_loss: 0.1028 - val_acc: 0.9674\n",
      "Epoch 9/20\n",
      "7104/7104 [==============================] - 3s 363us/step - loss: 0.1478 - acc: 0.9475 - val_loss: 0.1068 - val_acc: 0.9685\n",
      "Epoch 10/20\n",
      "7104/7104 [==============================] - 3s 362us/step - loss: 0.1523 - acc: 0.9452 - val_loss: 0.1078 - val_acc: 0.9702\n",
      "Epoch 11/20\n",
      "7104/7104 [==============================] - 3s 362us/step - loss: 0.1551 - acc: 0.9464 - val_loss: 0.1146 - val_acc: 0.9651\n",
      "Epoch 12/20\n",
      "7104/7104 [==============================] - 3s 361us/step - loss: 0.1382 - acc: 0.9520 - val_loss: 0.1160 - val_acc: 0.9634\n",
      "Epoch 13/20\n",
      "7104/7104 [==============================] - 3s 365us/step - loss: 0.1573 - acc: 0.9490 - val_loss: 0.1427 - val_acc: 0.9488\n",
      "Epoch 14/20\n",
      "7104/7104 [==============================] - 3s 363us/step - loss: 0.1397 - acc: 0.9506 - val_loss: 0.1225 - val_acc: 0.9600\n",
      "Epoch 15/20\n",
      "7104/7104 [==============================] - 3s 360us/step - loss: 0.1356 - acc: 0.9540 - val_loss: 0.1154 - val_acc: 0.9645\n",
      "Epoch 16/20\n",
      "7104/7104 [==============================] - 3s 362us/step - loss: 0.1322 - acc: 0.9554 - val_loss: 0.1208 - val_acc: 0.9617\n",
      "Epoch 17/20\n",
      "7104/7104 [==============================] - 3s 362us/step - loss: 0.1310 - acc: 0.9569 - val_loss: 0.1269 - val_acc: 0.9634\n",
      "Epoch 18/20\n",
      "7104/7104 [==============================] - 3s 361us/step - loss: 0.1415 - acc: 0.9510 - val_loss: 0.1300 - val_acc: 0.9589\n",
      "Epoch 19/20\n",
      "7104/7104 [==============================] - 3s 362us/step - loss: 0.1471 - acc: 0.9481 - val_loss: 0.1463 - val_acc: 0.9544\n",
      "Epoch 20/20\n",
      "7104/7104 [==============================] - 3s 362us/step - loss: 0.1390 - acc: 0.9507 - val_loss: 0.1376 - val_acc: 0.9578\n",
      "the loss 0.15450402783151954 and the accuracy score for test dataset is 0.9612787032868078\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('skipgram_model.h5'):\n",
    "    model = load_model('skipgram_model.h5')\n",
    "    train_test_model(model, data, labels,\"skipgram\")\n",
    "else:\n",
    "    model = defineModel(max_length, embedding_size, embedding_layer)\n",
    "    print(model.summary())\n",
    "    train_test_model(model, data, labels, \"skipgram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Gradient Boosting Classifier with doc2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_food = tweets_food.reset_index(drop=True)\n",
    "#transform the tweets text into the doc2vec compatible input format\n",
    "def label_sentences(df):\n",
    "    labeled_sentences = []\n",
    "    for index, row in df.iterrows():\n",
    "        #print(index)\n",
    "        tokenized_words = row[\"tweets_text\"].lower().split(\" \")\n",
    "        labeled_sentences.append(LabeledSentence(words=tokenized_words, tags=['label{}'.format(index)]))\n",
    "    return labeled_sentences\n",
    "\n",
    "#trains the doc2vec model\n",
    "def tweets_doc2vec_model(labeled_sentences):\n",
    "    model = Doc2Vec(alpha=0.01, min_alpha=0.01, min_count = 2)\n",
    "    model.build_vocab(labeled_sentences)\n",
    "    for epoch in range(10):\n",
    "        model.train(labeled_sentences)\n",
    "        model.alpha -= 0.002 \n",
    "        model.min_alpha = model.alpha\n",
    "    return model\n",
    "\n",
    "seq = label_sentences(tweets_food)\n",
    "model = tweets_doc2vec_model(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label_data                                        tweets_text  \\\n",
      "0           2  Note to self don t eat scones before training ...   \n",
      "1           0  I feel like my body is trying to get sick but ...   \n",
      "\n",
      "                                   vectorized_tweets  \n",
      "0  [-0.0965432, 0.08884, -0.0701348, -0.0383165, ...  \n",
      "1  [-0.00250567, -0.090926, 0.0238593, 0.0058652,...  \n"
     ]
    }
   ],
   "source": [
    "def vectorize_tweets(df,d2v_model):\n",
    "    y = []\n",
    "    comments = []\n",
    "    for i in range(0,df.shape[0]):\n",
    "        label = 'label{}'.format(i)\n",
    "        comments.append(d2v_model.docvecs[label])\n",
    "    df['vectorized_tweets'] = comments    \n",
    "    return df\n",
    "\n",
    "def train_classifier(X,y):\n",
    "    n_estimators = [500]\n",
    "    min_samples_split = [4]\n",
    "    min_samples_leaf = [3]\n",
    "\n",
    "    parameters = {'n_estimators': n_estimators, 'min_samples_leaf': min_samples_leaf,\n",
    "                  'min_samples_split': min_samples_split}\n",
    "\n",
    "    clf = GridSearchCV(GradientBoostingClassifier(random_state=7), cv=5, param_grid=parameters)\n",
    "    clf.fit(X, y)\n",
    "    return clf\n",
    "\n",
    "doc2vec_df = vectorize_tweets(tweets_food, model)\n",
    "print (doc2vec_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.537409919457 is the accuracy score of the best possible model on validation set\n",
      "0.541416566627\n"
     ]
    }
   ],
   "source": [
    "doc2vec_df.label_data = doc2vec_df.label_data.astype('category').cat.codes\n",
    "X_train, X_test, y_train, y_test = train_test_split(doc2vec_df.vectorized_tweets.T.tolist(), doc2vec_df.label_data, test_size=0.15, random_state=17)\n",
    "classifier = train_classifier(X_train,y_train)\n",
    "print (classifier.best_score_, \"is the accuracy score of the best possible model on validation set\")\n",
    "print (classifier.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
